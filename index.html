<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Research website of Dustin Tran, a Ph.D.
  student at Columbia.">
  <meta name="author" content="Dustin Tran">
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <title>Dustin Tran</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/main.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>
<body>
  <div class="container">

    <div class="row" style="padding:20px">

       <div class="hidden-xs col-sm-3 col-md-2" id="sidebar" role="navigation" style="margin-top:180px">
        <hr>
        <ul class="nav nav-pills nav-stacked">
          <li><a href="#publications">Publications</a></li>
          <li><a href="blog">Blog</a></li>
        </ul>
      </div>

      <div class="col-xs-12 col-sm-9 col-md-9">

        <div class="row">
          <img src="img/photo-border.png" class="pull-left" style="margin:20px
          20px 20px 0; height:140px; width:140px; border-radius:100%"/>
          <h1>Dustin Tran</h1>
          <p class="lead">
            Research Scientist at Google DeepMind<br>
            trandustin@google.com
            <br>
            <a href="https://twitter.com/dustinvtran" class="icon">
              <i class="fa fa-twitter fa-lg"></i>
            </a>
            <a href="https://scholar.google.com/citations?user=wVazIm8AAAAJ" class="icon">
              <i class="fa fa-graduation-cap fa-lg"></i>
            </a>
            <a href="https://github.com/dustinvtran" class="icon">
              <i class="fa fa-github fa-lg"></i>
            </a>
            <a href="blog" class="icon blog">Blog</a>
          </p>
        </div>

        <hr>

        <div class="row">
          <p>
          I am a staff research scientist at
          <a href="https://blog.google/technology/ai/april-ai-update">Google DeepMind</a>.
          I am interested in intelligence
          under themes like programs, neural nets, and probability.
          Currently, I lead evaluation for <a
          href="https://blog.google/technology/ai/try-bard">Bard</a>
          and also work on <a
            href="https://blog.google/technology/ai/google-io-2023-keynote-sundar-pichai/">Gemini</a>.
          </p>
          <p>
          My most notable works are in
          infrastructure (<a
            href="https://arxiv.org/abs/1811.02084">Mesh
            TensorFlow</a>, <a
            href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor</a>,
          <a
            href="https://github.com/tensorflow/probability">TensorFlow
            Probability</a>, <a
            href="https://github.com/blei-lab/edward">Edward</a>),
          modeling
          (<a href="https://arxiv.org/abs/1802.05751">Image Transformer</a>,
          <a href="https://arxiv.org/abs/1603.00788">Automatic
            Differentiation Variational Inference</a>),
          and
          evaluation
          (<a href="https://arxiv.org/abs/2207.07411">Plex</a>,
          <a href="https://arxiv.org/abs/2106.04015">Uncertainty
            Baselines</a>,
          <a href="https://arxiv.org/abs/1904.01685">Measuring
            Calibration</a>).
          </p>
          <p>
          I completed my Ph.D. at Columbia University advised by
          <a href="http://www.cs.columbia.edu/~blei/">David Blei</a>
          and <a href="http://www.stat.columbia.edu/~gelman/">Andrew
          Gelman</a>.
          </p><p>
          Some talks:
          </p>
          <ul>
            <li>
              <div class="btn-group-xs">
                <strong>Plex</strong> (2022)
                <a href="https://docs.google.com/presentation/d/1bTvqHh2kjF0UjxIxM-OWJcATeGrcF1IrVksBzVE7Ss0/edit?usp=sharing&resourcekey=0-Hdh487_jFj1eBIGDhktSfA"
                class="btn btn-default">Slides</a>
                <a href="https://icml.cc/virtual/2022/workshop/13457"
                class="btn btn-default">Video (1:21:26)</a>
              </div>
            </li>
            <li>
              <div class="btn-group-xs">
                <strong>Practical Uncertainty Estimation &
                  Out-of-Distribution Robustness in Deep
                  Learning</strong> (2020)
                <a href="https://slideslive.com/38935801"
                class="btn btn-default">Video & Slides</a>
              </div>
            </li>
          </ul><p>
          <strong><a href="cv.pdf">Curriculum Vitae</a></strong>
          </p>
        </div>

        <div class="row">
          <h2><a name="publications"></a>Publications</h2>
          <hr>
          <h3>Preprints</h3>
          <p>
          Some of my work is available as
          <a href="http://arxiv.org/a/tran_d_1.html">preprints on arXiv</a>.
          </p>
          <p>
            <strong>Larger language models do in-context learning
              differently</strong><br>
            Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson,
            Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou,
            Tengyu Ma</a>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2303.03846"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Scaling vision transformers to 22 billion parameters</strong><br>
            Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr
            Padlewski, Jonathan Heek, Justin Gilmer, Andreas Steiner,
            Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin,
            Rodolphe Jenatton, Lucas Beyer, Michael Tschannen, Anurag
            Arnab, Xiao Wang, Carlos Riquelme, Matthias Minderer,
            Joan Puigcerver, Utku Evci, Manoj Kumar, Sjoerd van
            Steenkiste, Gamaleldin F. Elsayed, Aravindh Mahendran,
            Fisher Yu, Avital Oliver, Fantine Huot, Jasmijn Bastings,
            Mark Patrick Collier, Alexey Gritsenko, Vighnesh
            Birodkar, Cristina Vasconcelos, Yi Tay, Thomas Mensink,
            Alexander Kolesnikov, Filip Pavetić, Dustin Tran, Thomas
            Kipf, Mario Lučić, Xiaohua Zhai, Daniel Keysers, Jeremiah
            Harmsen, Neil Houlsby</a>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2302.05442"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>A simple zero-shot prompt weighting technique to
              improve prompt ensembling in text-image
              models</strong><br>
            James Urquhart Allingham, Jie Ren, Michael W Dusenberry,
            Jeremiah Zhe Liu, Xiuye Gu, Yin Cui, Dustin Tran, Balaji
            Lakshminarayanan</a>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2302.06235"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Plex: Towards reliability using pretrained large
              model extensions</strong><br>
            Dustin Tran, Jeremiah Liu, Michael W.
            Dusenberry, Du Phan, Mark Collier, Jie Ren, Kehang Han, Zi
            Wang, Zelda Mariet, Huiyi Hu, Neil Band, Tim G. J. Rudner,
            Karan Singhal, Zachary Nado, Joost van Amersfoort, Andreas
            Kirsch, Rodolphe Jenatton, Nithum Thain, Honglin Yuan,
            Kelly Buchanan, Kevin Murphy, D. Sculley, Yarin Gal,
            Zoubin Ghahramani, Jasper Snoek, Balaji
            Lakshminarayanan<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2207.07411"
              class="btn btn-default">Paper</a>
             <a href="https://ai.googleblog.com/2022/07/towards-reliability-in-deep-learning.html"
             class="btn btn-default">Blog</a>
              <a href="https://goo.gle/plex-code"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Uncertainty Baselines: Benchmarks for Uncertainty
              & Robustness in Deep Learning</strong><br>
            Zachary Nado, Neil Band, Mark Collier, Josip Djolonga,
            Michael W. Dusenberry, Sebastian Farquhar, Angelos Filos,
            Marton Havasi, Rodolphe Jenatton, Ghassen Jerfel, Jeremiah
             Liu, Zelda Mariet, Jeremy Nixon, Shreyas Padhy, Jie Ren,
             Tim G. J. Rudner, Yeming Wen, Florian Wenzel, Kevin
             Murphy, D. Sculley, Balaji Lakshminarayanan, Jasper
             Snoek, Yarin Gal, Dustin Tran<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2106.04015"
              class="btn btn-default">Paper</a>
             <a href="https://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html"
             class="btn btn-default">Blog</a>
             <a href="https://github.com/google/uncertainty-baselines"
             class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>On the discrepancy between density estimation and
              sequence generation</strong><br>
            Jason Lee, Dustin Tran, Orhan Firat,
            Kyunghyun Cho<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2002.07233"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Measuring calibration in deep learning</strong><br>
            Jeremy Nixon, Michael Dusenberry, Linchuan Zhang, Ghassen
            Jerfel, Dustin Tran<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1904.01685"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>NeuTra-lizing bad geometry in Hamiltonian Monte
              Carlo using neural transport</strong><br>
            Matthew Hoffman, Pavel Sountsov, Joshua V. Dillon, Ian
            Langmore, Dustin Tran, Srinivas Vasudevan<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1903.03704"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
           <strong>TensorFlow Distributions</strong><br>
           Joshua V. Dillon, Ian Langmore, Dustin
           Tran, Eugene Brevdo, Srinivas Vasudevan, Dave
           Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A.
           Saurous<br>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1711.10604"
             class="btn btn-default">Paper</a>
             <a href="/papers/DillonEtAl2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/tensorflow/probability"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
            <strong>Edward: A library for probabilistic modeling,
            inference, and criticism</strong><br>
            Dustin Tran, Alp Kucukelbir, Adji B. Dieng,
            Maja Rudolph, Dawen Liang, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1610.09787"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org"
              class="btn btn-default">Website</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Model criticism for Bayesian causal inference</strong><br>
            Dustin Tran, Francisco J. R. Ruiz, Susan
            Athey, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1610.09037"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Stochastic gradient descent methods for estimation with
            large data sets</strong><br>
            Dustin Tran, Panos Toulis, Edoardo M.
            Airoldi<br>
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1509.06459"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <h3>2023</h3>
          <p>
            <strong>A brief tour of deep learning from a statistical
              perspective</strong><br>
            Eric Nalisnick, Padhraic Smyth, Dustin Tran<br>
            <em>Annual Review of Statistics and Its Application</em>, 2023
            <div class="btn-group-xs">
              <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-statistics-032921-013738"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <h3>2022</h3>
          <p>
            <strong>Simple and principled uncertainty estimation with
              deterministic deep learning via distance
              awareness</strong><br>
            Jeremiah Zhe Liu, Zi Lin, Shreyas Padhy, Dustin
              Tran, Tania Bedrax-Weiss, Balaji
            Lakshminarayanan<br>
            <em>Journal of Machine Learning Research</em>, 2022
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2006.10108"
              class="btn btn-default">Paper</a>
             <a href="https://github.com/google/uncertainty-baselines"
             class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Sparse MoEs meet efficient ensembles</strong><br>
            James Urquhart Allingham, Florian Wenzel, Zelda E Mariet,
            Basil Mustafa, Joan Puigcerver, Neil Houlsby, Ghassen
            Jerfel, Vincent Fortuin, Balaji Lakshminarayanan, Jasper
            Snoek, Dustin Tran, Carlos Riquelme Ruiz, Rodolphe
            Jenatton<br>
            <em>Transactions on Machine Learning Research</em>, 2022
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2110.03360"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Deep classifiers with label noise modeling and
              distance awareness</strong><br>
            Vincent Fortuin, Mark Collier, Florian Wenzel, James
            Allingham, Jeremiah Liu, Dustin Tran,
            Balaji Lakshminarayanan, Jesse Berent, Rodolphe Jenatton,
            Effrosyni Kokiopoulou<br>
            <em>Transactions on Machine Learning Research</em>, 2022
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2110.02609"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <h3>2021</h3>
          <p>
            <strong>Revisiting the calibration of modern neural
              networks</strong><br>
            Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances
            Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, Mario
            Lucic<br>
            <em>Neural Information Processing Systems</em>, 2021
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2106.07998"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google-research/robustness_metrics/tree/master/robustness_metrics/projects/revisiting_calibration"
              class="btn btn-default">Code</a>
              <a href="https://neurips.cc/virtual/2021/poster/27728"
              class="btn btn-default">Video</a>
            </div>
          </p>
          <p>
            <strong>Benchmarking Bayesian deep learning on diabetic
              retinopathy detection tasks</strong><br>
            Neil Band, Tim G. J. Rudner, Qixuan Feng, Angelos Filos,
            Zachary Nado, Michael W Dusenberry, Ghassen Jerfel,
            Dustin Tran, Yarin Gal<br>
            <em>Neural Information Processing Systems</em>, 2021
            <div class="btn-group-xs">
              <a href="https://openreview.net/forum?id=jyd4Lyjr2iB"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Soft calibration objectives for neural networks</strong><br>
            Archit Karandikar, Nicholas Cain, Dustin
            Tran, Balaji Lakshminarayanan, Jonathon Shlens,
            Michael C. Mozer, Becca Roelofs<br>
            <em>Neural Information Processing Systems</em>, 2021
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2108.00106"
              class="btn btn-default">Paper</a>
              <a href="https://neurips.cc/virtual/2021/poster/26792"
              class="btn btn-default">Video</a>
            </div>
          </p>
          <p>
            <strong>Sampling the variational posterior with local
              refinement</strong><br>
            Marton Havasi, Jasper Snoek, Dustin Tran,
            Jonathan Gordon, José Miguel Hernández-Lobato<br>
            <em>Entropy</em>, 2021
            <div class="btn-group-xs">
              <a href="https://www.mdpi.com/1099-4300/23/11/1475/htm"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Combining ensembles and data augmentation can harm
              your calibration</strong><br>
            Yeming Wen, Ghassen Jerfel, Rafael Muller, Michael W.
            Dusenberry, Jasper Snoek, Balaji Lakshminarayanan,
            Dustin Tran<br>
            <em>International Conference on Learning Representations</em>, 2021
            <div class="btn-group-xs">
              <a href="https://openreview.net/forum?id=g11CZSghXyY"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google/edward2/tree/master/experimental/marginalization_mixup"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Training independent subnetworks for robust prediction</strong><br>
            Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah
            Zhe Liu, Jasper Snoek, Balaji Lakshminarayanan, Andrew M.
            Dai, Dustin Tran<br>
            <em>International Conference on Learning Representations</em>, 2021
            <div class="btn-group-xs">
              <a href="https://openreview.net/forum?id=OGg9XnKxFAH"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google/edward2/tree/master/experimental/mimo"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <h3>2020</h3>
          <p>
            <strong>Hyperparameter ensembles for robustness and
              uncertainty quantification</strong><br>
            Integrate over both weights and hyperparameters!
            <br>
            Florian Wenzel, Jasper Snoek, Dustin
            Tran, Rodolphe Jenatton<br>
            <em>Neural Information Processing Systems</em>, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2006.13570"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google/uncertainty-baselines"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Simple and principled uncertainty estimation with
              deterministic deep learning via distance
              awareness</strong><br>
            Leverage spectral normalization and Gaussian processes.
            <br>
            Jeremiah Zhe Liu, Zi Lin, Shreyas Padhy, Dustin
            Tran, Tania Bedrax-Weiss, Balaji
            Lakshminarayanan<br>
            <em>Neural Information Processing Systems</em>, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2006.10108"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google/uncertainty-baselines"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Demonstrating principled uncertainty modeling for
              recommender ecosystems with RecSim NG</strong><br>
            A platform for simulating multi-agent recommender systems
            using probabilistic programming.
            <br>
            Martin Mladenov, Chih-Wei Hsu, Vihan Jain, Eugene Ie,
            Christopher Colby, Nicolas Mayoraz, Hubert Pham,
            Dustin Tran, Ivan Vendrov, Craig
            Boutilier<br>
            <em>RecSys</em>, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2103.08057"
              class="btn btn-default">Paper</a>
             <a href="https://ai.googleblog.com/2021/04/flexible-scalable-differentiable.html"
             class="btn btn-default">Blog</a>
             <a href="https://github.com/google-research/recsim_ng"
             class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Efficient and scalable Bayesian neural nets with
              rank-1 factors</strong><br>
            Mixture posteriors, Cauchy priors, rank-1
            parameterization.
            <br>
            Michael Dusenberry, Ghassen Jerfel, Yeming Wen, Yi-an Ma,
            Jasper Snoek, Katherine Heller, Balaji Lakshminarayanan,
            Dustin Tran<br>
            <em>International Conference on Machine Learning</em>, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2005.07186"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google/edward2"
              class="btn btn-default">Code</a>
              <a href="https://icml.cc/virtual/2020/poster/6680"
              class="btn btn-default">Video</a>
            </div>
          </p>
          <p>
            <strong>BatchEnsemble: An alternative approach to
              efficient ensemble and lifelong learning</strong><br>
            Efficient ensembles for uncertainty and lifelong learning.
            <br>
            Yeming Wen, Dustin Tran, Jimmy Ba<br>
            <em>International Conference on Learning Representations</em>, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/2002.06715"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/google/edward2"
              class="btn btn-default">Code</a>
              <a href="https://iclr.cc/virtual_2020/poster_Sklf1yrYDr.html"
              class="btn btn-default">Video</a>
            </div>
          </p>
          <p>
            <strong>Analyzing the role of model uncertainty in
              electronic health records</strong><br>
            Where parameter uncertainty affects clinical decision-making.
            <br>
            Michael Dusenberry, Dustin Tran, Edward
            Choi, Jonas Kemp, Jeremy Nixon, Ghassen Jerfel, Katherine
            Heller, Andrew Dai<br>
            <em>ACM Conference on Health, Inference, and Learning</em>, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1906.03842"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Expectation propagation as a way of life: A
            framework for Bayesian inference on partitioned
            data</strong><br>
            How to distribute inference with massive data sets and how
            to combine inferences from many data sets.
            <br>
            Andrew Gelman, Aki Vehtari, Pasi Jylänki, Tuomas Sivula,
            Dustin Tran, Swupnil Sahai, Paul
            Blomstedt, John P. Cunningham, David Schiminovich,
            Christian Robert<br>
            <em>Journal of Machine Learning Research</em>, 21(17):1–53, 2020
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1412.4869"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <h3>2019</h3>
          <p>
            <strong>Bayesian Layers: A module for neural network uncertainty</strong><br>
            A neural net-stylized primitive for distributions over functions.
            <br>
            Dustin Tran, Michael Dusenberry, Mark van
            der Wilk, Danijar Hafner<br>
            <em>Neural Information Processing Systems</em>, 2019
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1812.03973"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranDusenberryVanDerWilkHafner2019_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/google/edward2"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Discrete flows: Invertible generative models for
              discrete data</strong><br>
            How to model with discrete invertible functions.<br>
            Dustin Tran, Keyon Vafa, Kumar Krishna
            Agrawal, Laurent Dinh, Ben Poole<br>
            <em>Neural Information Processing Systems</em>, 2019
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1905.10347"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranVafaAgrawalDinhPoole2019_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/google/edward2"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
           <strong>Noise contrastive priors for functional uncertainty</strong><br>
           A prior for neural networks in data space.
           <br>
           Danijar Hafner, Dustin Tran, Alex Irpan,
           Timothy Lillicrap, James Davidson<br>
           <em>Uncertainty in Artificial Intelligence</em>, 2019
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1807.09289"
             class="btn btn-default">Paper</a>
             <a href="/papers/HafnerTranIrpanLillicrapDavidson2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/brain-research/ncp"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <h3>2018</h3>
          <p>
           <strong>Simple, distributed, and accelerated probabilistic
           programming</strong><br>
           Probabilistic programs on TPUs.
           <br>
           Dustin Tran, Matthew D. Hoffman, Dave
           Moore, Christopher Suter, Srinivas Vasudevan, Alexey Radul,
           Matthew Johnson, Rif A. Saurous<br>
           <em>Neural Information Processing Systems</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1811.02091"
             class="btn btn-default">Paper</a>
             <a href="/papers/TranHoffmanMooreSuterVasudevanRadulJohnsonSaurous2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/google-research/google-research/tree/master/simple_probabilistic_programming"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Autoconj: Recognizing and exploiting conjugacy
           without a domain-specific language</strong><br>
           The autointegrate analog of autodiff.
           <br>
           Matthew D. Hoffman, Matthew Johnson, Dustin Tran<br>
           <em>Neural Information Processing Systems</em>, 2018
           <div class="btn-group-xs">
             <a href="https://papers.nips.cc/paper/8270-autoconj-recognizing-and-exploiting-conjugacy-without-a-domain-specific-language"
             class="btn btn-default">Paper</a>
             <a href="/papers/HoffmanJohnsonTran2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/google-research/autoconj"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Mesh-TensorFlow: Deep learning for
             supercomputers</strong><br>
           Model parallelism made easier.
           <br>
	   Noam Shazeer, Youlong Cheng, Niki Parmar, Dustin
           Tran, Ashish Vaswani, Penporn Koanantakool, Peter Hawkins,
	   HyoukJoong Lee, Mingsheng Hong, Cliff Young, Ryan Sepassi, Blake
           Hechtman<br>
           <em>Neural Information Processing Systems</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1811.02084"
             class="btn btn-default">Paper</a>
             <a href="/papers/ShazeerEtAl2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/tensorflow/mesh"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Image Transformer</strong><br>
           An image autoregressive model using only attention.
           <br>
           Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam
           Shazeer, Alexander Ku, Dustin Tran<br>
           <em>International Conference on Machine Learning</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1802.05751"
             class="btn btn-default">Paper</a>
             <a href="/papers/ParmarVaswaniUszkoreitKaiserShazeerKuTran2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/tensorflow/tensor2tensor"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Implicit causal models for genome-wide association
           studies</strong><br>
           Generative models applied to causality in genomics.
           <br>
           Dustin Tran, David M. Blei<br>
           <em>International Conference on Learning Representations</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1710.10742"
             class="btn btn-default">Paper</a>
             <a href="/papers/TranBlei2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://www.youtube.com/watch?v=gi2jZ_bVJuA&index=6&list=PL6_fD5q0zQxshmFJCSBaA5Jglf62Ct4Vm"
             class="btn btn-default">Video</a>
             <a href="/talks/Tran_Genomics.pdf"
             class="btn btn-default">Slides</a>
           </div>
          </p>
          <p>
           <strong>Flipout: Efficient pseudo-independent weight perturbations
           on mini-batches</strong><br>
           How to make weight perturbations in evolution strategies and
           variational BNNs as mini-batch-friendly as activation perturbations
           in dropout and batch norm.
           <br>
           Yeming Wen, Paul Vicol, Jimmy Ba, Dustin Tran,
           Roger Grosse<br>
           <em>International Conference on Learning Representations</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1803.04386"
             class="btn btn-default">Paper</a>
             <a href="https://github.com/tensorflow/tensor2tensor"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <h3>2017</h3>
          <p>
            <strong>Hierarchical implicit models and likelihood-free
            variational inference</strong><br>
            Combining the idea of implicit densities with hierarchical Bayesian
            modeling and deep neural networks.
            <br>
            Dustin Tran, Rajesh Ranganath, David M.
            Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranRanganathBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="http://dustintran.com/blog/deep-and-hierarchical-implicit-models"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Variational inference via $\chi$-upper bound
            minimization</strong><br>
            Overdispersed approximations and upper bounding
            the model evidence.
            <br>
            Adji B. Dieng, Dustin Tran, Rajesh
            Ranganath, John Paisley, David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/BoussoTranRanganathPaisleyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/blei-lab/edward"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Comment, "Fast approximate inference for
            arbitrarily large semiparametric regression models via
            message passing"</strong><br>
            The role of message passing in automated inference.
            <br>
            Dustin Tran, David M. Blei<br>
            <em>Journal of the American Statistical Association</em>,
            112(517):156–158, 2017
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1609.05615"
              class="btn btn-default">Paper</a>
              <a href="http://dustintran.com/blog/discussion-of-fast-approximate-inference"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Automatic differentiation variational inference</strong><br>
            An automated tool for black box variational inference,
            available in Stan.
            <br>
            Alp Kucukelbir, Dustin Tran, Rajesh Ranganath,
            Andrew Gelman, David M. Blei<br>
            <em>Journal of Machine Learning Research</em>, 18(14):1–45, 2017
            <div class="btn-group-xs">
              <a href="/papers/KucukelbirTranRanganathGelmanBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/stan-dev/stan"
              class="btn btn-default">Code</a>
              <a href="/talks/Tran_Automating.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Deep probabilistic programming</strong><br>
            How to build a language with rich compositionality for
            modeling and inference.
            <br>
            Dustin Tran, Matthew D. Hoffman, Rif A.
            Saurous, Eugene Brevdo, Kevin Murphy, David M. Blei<br>
            <em>International Conference on Learning Representations</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranHoffmanSaurousBrevdoMurphyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org/iclr2017"
              class="btn btn-default">Website</a>
              <a href="/papers/TranHoffmanMurphyBrevdoSaurousBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2016</h3>
          <p>
            <strong>Operator variational inference</strong><br>
            How to formalize computational and statistical tradeoffs in variational inference.
            <br>
            Rajesh Ranganath, Jaan Altosaar, Dustin Tran, and David M.
            Blei<br>
            <em>Neural Information Processing Systems</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathAltosaarTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathAltosaarTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Hierarchical variational models</strong><br>
            A Bayesian formalism for constructing expressive
            variational families.
            <br>
            Rajesh Ranganath, Dustin Tran, David M.
            Blei<br>
            <em>International Conference on Machine Learning</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Spectral M-estimation with application to hidden
            Markov models</strong><br>
            Applying M-estimation for sample efficiency and robustness
            in moment-based estimators.
            <br>
            Dustin Tran, Minjae Kim, Finale Doshi-Velez<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranKimDoshi-Velez2016.pdf"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Towards stability and optimality in stochastic gradient
            descent</strong><br>
            A stochastic gradient method combining numerical stability
            and statistical efficiency.
            <br>
            Panos Toulis, Dustin Tran, Edoardo M.
            Airoldi<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/ToulisTranAiroldi2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/ToulisTranAiroldi2016_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>The variational Gaussian process</strong><br>
            A powerful variational model that can universally
            approximate any posterior.
            <br>
            Dustin Tran, Rajesh Ranganath, David M.
            Blei<br>
            <em>International Conference on Learning Representations</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/talks/Tran_Variational.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2015</h3>
          <p>
            <strong>Copula variational inference</strong><br>
            Posterior approximations using copulas, which find
            meaningful dependence between latent variables.
            <br>
            Dustin Tran, David M. Blei, Edoardo M.
            Airoldi<br>
            <em>Neural Information Processing Systems</em>, 2015
            <div class="btn-group-xs">
              <a href="/papers/TranBleiAiroldi2015.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranBleiAiroldi2015_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
        </div>

      </div>

    </div>

    <hr>

    <footer>
    &nbsp;
    </footer>

  </div>

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'] ],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/js/main.js"></script>
</body>
</html>
